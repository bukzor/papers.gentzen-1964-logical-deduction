
AMERICAN PHILOSOPHICAL QUARTERLY
Volume 1, Number 4, October 1964

## II. "INVESTIGATIONS INTO LOGICAL DEDUCTION"*

GERHARD GENTZEN

## INTRODUCTION

**G**ERHARD GENTZEN's inaugural disserta-
tion for the University of Göttingen, "*Unter-
suchungen über das logische Schliessen*," of which Mr.
Manfred Szabo here presents an English transla-
tion, is an important step in the deeper analysis of
the logical calculus as it was begun in the thesis of
Jacques Herbrand. In it Gentzen develops a new
form of logical calculus, the "calculus of sequents,"
which he introduces by starting first from a
"natural calculus" and by then transforming it
for his technical purposes. Its central theorem, an
"elimination theorem," is proved in detail in the
first part of the paper. The second part deals with
applications of this elimination theorem as well as
containing the proof of the equivalence of the
calculus of sequents with usual logical
calculus.

The *Untersuchungen* have had a profound
influence on the development of mathematical
logic and proof theory. The treatment of the
calculus of sequents has been extended by Oiva
Ketonen (in Finland) and by Haskell B. Curry (in
the U.S.A.), and the elimination theorem of
Gentzen has been transferred by Kurt Schütte to
the usual logical calculus. The application of the
elimination theorem to proof theory has been
developed by Paul Lorenzen and Kurt Schütte
through the use of "infinitic induction." Lately
Gaisi Takeuti (in Japan) has generalized the
Gentzen calculus to a system of type theory in
which the theory of real numbers can be formalized.
Here the elimination theorem is not yet proved,
but Takeuti shows that upon the assumption of the
generalized elimination theorem the consistency
of his system follows.

Thus Gentzen's *Untersuchungen* are of great

current interest, and an English edition of this
treatise is to be very much welcomed.

PAUL BERNAYS

(Part I)

SYNOPSIS

The investigations that follow concern the
domain of *predicate logic*, called by H-A¹ the "lower
functional calculus." It comprises the types of
inference that are continually used in all parts of
mathematics. What remains to be added to these
are axioms for the various of inference laws to be
considered as being proper to the particular
branches of mathematics, e.g., in elementary
number theory the axioms of the natural numbers,
of addition, multiplication, and exponentiation, as
well as the inference of complete induction, in
geometry the geometric axioms.

In addition to *classical logic* I shall also deal with
*intuitionist logic* as formalized, for example, by
Heyting².

The present investigations into classical and
intuitionist predicate logic fall essentially into two
more closely connected parts.

1. My starting point was this: The formalization
of logical deduction, especially as it has been
developed by Frege, Russell, and Hilbert, is rather
far removed from the forms of deduction used in
practice in mathematical proofs. Considerable
formal advantages are achieved in return. I
intended, first of all, to set up a formal system which
came as close as possible to actual reasoning. The
result was a "*calculus of natural deduction*." ("*NJ*"
for intuitionism, "*NK*" for classical predicate logic.)
This calculus then turned out to have specific pro-
perties; in particular, the "law of the excluded
middle," which intuitionists reject, occupies a
special position.

* Originally published in the *Mathematische Zeitschrift*, vol. 39 (1935), pp. 176–221. A second part of these investigations
appeared under the same title, *ibid.*, pp. 405–431. The *American Philosophical Quarterly* plans to publish this at a later date. The
present English translation is by Mr. M. E. Szabo (McGill University, Montreal) whose thanks are due to his wife Ann
for her continued encouragement, and to Mr. Michael Dummett of All Souls College, Oxford, for reading the translation
and suggesting improvements.

¹ Hilbert-Ackermann, *Grundzüge der theoretischen Logik*, in this paper referred to as H–A.

² A. Heyting, *Die formalen Regeln der intuitionistischen Logik und Mathematik*, Sitzungsber. d. Preuß. Akad. d. Wiss., phys.-math.
Kl. 1930, pp. 42–65.

I shall develop the calculus of natural deduction
in the second Section of this paper together with
some remarks concerning it.

2. A closer investigation of the specific properties
of this calculus have finally led me to a very
general theorem which will be referred to below as
the "*Hauptsatz*."

The *Hauptsatz*³ says that every purely logical
proof can be reduced to a determinate, though not
unique, normal form. Perhaps we may express the
essential properties of such a normal form by
saying "it is not roundabout." No concepts enter
into the proof other than those contained in its
final result, and their use was therefore essential to
the achievement of that result.

The *Hauptsatz* is valid both for classical and for
intuitionist predicate logic.

In order to be able to enunciate and prove the
*Hauptsatz* in a convenient form, I had to provide a
logical calculus especially suited to the purpose. For
this the natural calculus proved unsuitable. For,
although it already contains the properties essential
to the validity of the *Hauptsatz*, it does so only with
respect to its intuitionist form, in view of the fact
that the law of excluded middle, as pointed out
earlier, occupies a special position in relation to
these properties.

In Section III of this paper, therefore, I shall
develop a new calculus of logical deduction con-
taining all the desired properties in both their
intuitionist and their classical form. ("*LJ*" for
intuitionist, "*LK*" for classical predicate logic.)
The *Hauptsatz* will then be enunciated and proved
by means of that calculus.

The *Hauptsatz* permits of a variety of *applications*.
To illustrate this I shall develop a decision pro-
cedure (IV, §1) for intuitionist propositional logic
in Section IV, and shall in addition give a new
proof of the consistency of classical arithmetic
without complete induction (IV, §3).

Sections III and IV may be read independently
of Section II.

3. Section I contains the stipulation of the terms
and notations used in this paper.

In Section V, I prove the *equivalence* of the logical
calculi *NJ*, *NK*, and *LJ*, *LK*, developed in this
paper, by means of a calculus modeled on the

formalisms of Russell, Hilbert, and Heyting (and
which may easily be compared with them).
("*LHJ*" for intuitionist, "*LHK*" for classical pre-
dicate logic.)

4. Only the first part of my paper containing
Sections I to III is presented here. Sections IV and
V follow in the second part.

**Section I.**

**Stipulation of Terms**

To the concepts "object," "function," "predic-
ate," "proposition," "theorem," "axiom," "proof,"
"inference," etc., in logic and mathematics there
correspond, in the formalization of these disciplines,
certain symbols or combinations of symbols. We
divide these into:

1. *Symbols*.
2. *Expressions*, i.e., finite series of symbols.
3. *Figures*, i.e., finite sets of symbols, with some
ordering.

Symbols count as special cases of expressions and
figures; expressions as special cases of figures.

In this paper we shall consider symbols, expres-
sions, and figures of the following kind:

1. *Symbols*.

These divide into constant symbols and vari-
ables.

1.1 Constant symbols:

*Symbols for particular objects*: 1, 2, 3, . . .

*Symbols for particular functions*: +, −, •.

*Symbols for particular propositions*: **T** ("the true
proposition"), **F** ("the false proposition").

*Symbols for particular predicates*: =, <.

*Logical symbols*: & "and", ∨ "or", ⊃ "if . . .
then," ⊃⊂ "is equivalent to," ¬ "not", ∀
"for all," ∃ "there is a."

We shall also use the terms: conjunction symbol,
disjunction symbol, implication symbol, equiva-
lence symbol, negation symbol, universal quantifier,
existential quantifier.

*Auxiliary symbols*: ), (, →.

1.2 Variables:

*Object variables*. These we divide into *free* object
variables: *a*, *b*, *c*, . . . *m* and *bound* object variables:
*n*, . . . *x*, *y*, *z*.

*Propositional variables*: *A*, *B*, *C*, . . .

² An important special case of the *Hauptsatz* had already been proved in a completely different way by Herbrand, cf. Section
iv, §2.

³ We take the symbols ∨, ⊃, ∃ from Russell. Russell's symbols for "and," "equivalent," "not," "all," viz: •, ≡, ∼, ( ), are
already being used with a different meaning in mathematics. We shall therefore take Hilbert's &, whereas Hilbert's symbols
for equivalence, all, and not, viz.: ∼, ( ), ¯, again have already different meanings. Besides, the negation symbol represents
a departure from the linear arrangement of symbols and is inconvenient for some purposes. We shall therefore use Heyting's
symbols for equivalence and negation, and for "all" we shall use the inverted German A [namely: ∀] common to ∃.

We assume that an indefinite number of variables
is available; if the alphabet does not suffice, we add
numerical subscripts such as x₇, C₃.

1.3. Boldface and Greek letters serve as "syn-
tactic variables," i.e., not as symbols of the logic
formalized, but as variables of our considerations
*concerning* that logic. Their meaning is explained as
they are used.

2. *Expressions*.

2.1. The concept of a propositional expression,
called a "*formula*" for short (defined inductively):
(The concept of a formula is ordinarily used in a
more general sense; the special case defined below
might thus perhaps be described as a "purely
logical formula.")

2.11. A symbol for a particular proposition (i.e.,
capital letter A and F) is a formula.

A propositional variable followed by a number
(possibly zero) of free object variables is a formula,
e.g., *Abab*.

The object variables are called the *arguments* of
the propositional variables.

Formulae of the two kinds mentioned are also
called *elementary formulae*.

2.12. If A is a formula, then ¬ A is also a
formula.

If A and B are formulae, then A&B, A∨B,
A⊃B are formulae.

(We shall not introduce the symbol ⊃⊂ into
our presentation; it is in fact superfluous, since
A⊃⊂B may be regarded as an abbreviation of
(A⊃B) & (B⊃A).)

2.13. A formula not containing the bound object
variable x yields another formula, if we prefix
either ∀x or ∃x. At the same time we may substi-
tute x in a number of places for a free object
variable occurring in the formula.

2.14. Brackets (or parentheses) are to be used to
show the structure of a formula unequivocally.
Example of a formula:

∃x ( ( (¬Abxa) ∨ Bx) ⊃ (∀ z(A&B) ) )

By special convention the number of brackets
may be reduced, but (with one exception, *vide* 2.4)
no use will be made of this, since we do not have to
write down many formulae.

2.2. The number of logical symbols occurring in
a formula is called the *grade of a formula*. (Thus an
elementary formula is of grade 0.)

The logical symbol of a non-elementary formula
that has been added last, in the construction of the
formula according to 2.11 and 2.12, is called the
*terminal symbol of a formula*.

Formulae that may have arisen in the course of
the construction of a formula according to 2.12 and
2.13, including the formula itself, are called *sub-
formulae*.

Example: the subformulae of A& ∀ xBxa are
A, ∀xBxa, A& ∀xBxa, as well as all formulae of the
form Baa, where a represents any free object
variable (this variable may also be a, for example).
The grade of A& ∀ xBxa is 2, the terminal symbol
is &.

2.3. The concept of a *sequent*:

(This concept will not be used until Section III,
and it is only then that the purpose of its intro-
duction becomes apparent.)

A sequent is an expression of the form

A₁, . . . , Aₙ —→ B₁, . . . , Bᵥ,

where A₁, . . . , Aₙ, B₁, . . . , Bᵥ may represent any
formulae whatever. (The —→, like commas, is an
auxiliary symbol and not a logical symbol.)

The formulae A₁, . . . , Aₙ forms the *antecedent*,
and the formulae B₁, . . . , Bᵥ, the *succedent* of the
sequent. (This sequent may be empty.)

2.4. The sequent A₁, . . . , Aₙ —→ B₁, . . . , Bᵥ has
exactly the same intuitive meaning as the formula

(A₁& . . . &Aₙ) ⊃ (B₁ ∨ . . . ∨ Bᵥ).

(By A₁&A₂&A₃ we mean (A₁&A₂)&A₃, likewise
for ∨ .)

If the antecedent is empty, the sequent reduces
to the formula B₁ ∨ . . . ∨ Bᵥ.

If the succedent is empty, the sequent means the
same as the formula ¬(A₁& . . . &Aₙ) or (A₁& . . .
&Aₙ)⊃F.

If both parts of the formula are empty, the
sequent means the same as F, i.e., a false propo-
sition.

Conversely, to every formula there corresponds
an equivalent sequent, e.g., that one whose
antecedent is empty and whose succedent consists
precisely of that formula.

The formulae making up a sequent are called
*S-formulae* (i.e., sequent formulae). By this we
intend to indicate that we are not considering the
formula by itself, but as it appears in the sequent.
Thus we say, for example:

"A formula occurs in several places in a sequent
as an S-formula"; which may also be expressed as
follows:

"Several distinct S-formulae (which shall simply
mean: in several different occurrences in the sequent)
are formally identical."

3. *Figures*.

We require inference figures and proof figures.
Such figures consist of formulae or sequents, as
the case may be. In what follows (3.1 to 3.3, 3.5)
we shall be speaking only of formulae, but whatever
is said applies analogously to sequents; all we need
to do is to replace the word "formula," wherever it
occurs, by the word "sequent."

3.1. An *inference figure* may be written in the
following way:

```txt
A₁, . . . , Aᵥ
─────────────  (ν ≥ 1),
      B
```

where A₁, . . . , Aᵥ, B are formulae. A₁, . . . , Aᵥ
are then called the *upper formulae* and B the *lower
formula* of the inference figure. (The concepts of an
upper sequent and of a lower sequent of an infer-
ence figure consisting of sequents are to be under-
stood correspondingly.)

We shall have to consider only particular
inference figures and they will be stated for each
calculus as they arise.

3.2. An inference figure, called a *derivation* for short,
consists of a number of formulae (at least one),
which combine to form inference figures in the
following way: Each formula is a lower formula of
at most one inference figure; each formula (with
the exception of exactly one: the *endformula*) is an
upper formula of at least one inference figure; and
the system of inference figures is non-circular, i.e.,
there is in the derivation no cycle (no series whose
last member is again succeeded by its first member)
of formulae of which each upper formula of an
inference figure has the lower formula as the next
one in the series.

3.3. The formulae of a derivation that are not
lower formulae of an inference figure are called
*initial formulae* of the derivation.

A derivation is in "tree form" if every one of its
formulae is an upper formula of *at most one* inference
figure.

Thus all formulae except the endformula are
upper formulae of *exactly one* inference figure.

We shall have to treat only of derivations in tree
form.

The formulae which compose a derivation so
defined are called *D-formulae* (i.e., derivation
formulae). By this we wish to indicate that we are
not considering merely the formula as such, but
also its position in the derivation. In this sense we
shall be using, for example, expressions such as:

"A formula occurs in a derivation as a *D-
formula*."

"Two distinct *D*-formulae (i.e., formulae occur-
ring merely in distinct places in the derivation) are
formally identical, viz., identical to the same
formula."

By saying "**A is the *same D*-formula as B**" we mean
that **A** and **B** are not only formally identical, but
occur also in the same place in the derivation. We
shall use the words "formally identical" to indicate
identity of form regardless of place.

For object variables, however, we shall not
introduce a special term that would associate the
variable with a specific place of occurrence in the
formula. Thus we say, e.g.: "*The same* object
variable occurs in two distinct *D*-formulae."

3.4. The inference figures of the derivation are
called *D-inference figures* (i.e., derivation inference
figures).

In a derivation consisting of sequents the *S*-
formulae of the *D*-sequents are called *D-S-
formulae* (i.e., derivation sequent formulae).

3.5. A *branch* in a derivation is (following Hilbert)
a series of *D*-formulae whose first formula is an
initial formula and whose last formula is the end-
formula, and of which each formula except the last
is an upper formula of a *D*-inference figure whose
lower formula is the next formula in the branch.

We say that "a *D*-formula stands *above* (*below*)
another *D*-formula" if there exists a branch in
which the former occurs before (after) the latter.

We are here thinking of the fact that a derivation
is written in tree form with the initial formula
above and the endformula below. (Examples may
be found in II, §4).

Furthermore, we say that "a *D*-inference figure
occurs above (below) a *D*-formula," if all formulae
of the inference figure occur above (below) that
*D*-formula.

A derivation with the endformula **A** is also called
a "derivation of **A**."

The initial formulae of a derivation may be *basic
formulae* or *assumption formulae*; more about their
nature will have to be said as we reach the different
calculi.

SECTION II.

THE CALCULUS OF NATURAL DEDUCTION

§ 1

*Examples of Natural Deduction*

We wish to set up a formalism that reflects as
accurately as possible the actual logical reasoning
involved in mathematical proofs.

By means of a number of examples we shall first
of all show what form actual reasoning tends to take
and shall examine, for this purpose, three "valid
formulae" and try to see their validity in the most
natural way possible.

1.1. *First example*:
(𝑋∨(𝑌&𝑍))⊃((𝑋∨𝑌)&(𝑋∨𝑍)) can be re-
cognized as a valid formula (H–A, p. 28, formula
19).

The argument runs as follows. Suppose that
either 𝑋 or 𝑌&𝑍 holds. We distinguish the two
cases: 1. 𝑋 holds, 2. 𝑌&𝑍 holds. In the first case it
follows that 𝑋∨𝑌 holds, and also 𝑋∨𝑍; hence
(𝑋∨𝑌) & (𝑋∨𝑍) also holds. In the second case
𝑌&𝑍 holds, which means that both 𝑌 and 𝑍 hold.
From 𝑌 follows 𝑋∨𝑌; from 𝑍 follows 𝑋∨𝑍. Thus
(𝑋∨𝑌)&(𝑋∨𝑍) again holds. The latter formula
has thus been derived, in general, from 𝑋∨(𝑌&𝑍),
i.e.,

(𝑋∨(𝑌&𝑍))⊃((𝑋∨𝑌)&(𝑋∨𝑍)) holds.

1.2. *Second example*:
(∃𝑥∀𝑦𝐹𝑥𝑦)⊃(∀𝑦∃𝑥𝐹𝑥𝑦).
(H–A, formula 36, p. 60). The argument runs
as follows: Suppose there is an 𝑥 such that for all 𝑦
𝐹𝑥𝑦 holds. Let 𝑎 be such an 𝑥. Then for all 𝑦: 𝐹𝑎𝑦
holds. Now let 𝑏 be an arbitrary object. Then 𝐹𝑎𝑏
holds. Thus there is an 𝑥, viz., 𝑎, such that 𝐹𝑥𝑏
holds. Since 𝑏 was arbitrary, our result therefore
holds for all objects, i.e., for all 𝑦 there is an 𝑥, such
that 𝐹𝑥𝑦 holds. This yields our assertion.

1.3. *Third example*:
(⌐∃𝑥𝐹𝑥)⊃(∀𝑦⌐𝐹𝑦) is to be recognized as
intuitionistically valid. We reason as follows:
Assume there were no 𝑥 for which 𝐹𝑥 held. From
this we wish to infer: For all 𝑦, ⌐𝐹𝑦 holds. Now
suppose 𝑎 were some object for which 𝐹𝑎 held. It
would then follow that there was an 𝑥 for which
𝐹𝑥 held, viz., 𝑎 would be such an object. This
contradicts our hypothesis that ⌐∃𝑥𝐹𝑥. We have
therefore a contradiction, i.e., 𝐹𝑎 cannot hold. But
since 𝑎 was completely arbitrary, it follows that for
all 𝑦, ⌐𝐹𝑦 holds. Q.E.D.

We intend now to integrate proofs of the kind
carried out in these three examples in an exactly
defined calculus (in §4, we shall show how these
examples are presented in that calculus).

§2.

*Construction of the Calculus 𝒩𝒥*

2.1. We intend now to present a calculus for
"natural" intuitionist derivations of valid formulae.

The restriction to intuitionist reasoning is only
provisional; we shall explain below (cf. §5) our
reasons for doing so and shall show in what
way the calculus has to be extended for classical
reasoning (by including the law of the excluded
middle).

Externally, the essential difference between
"𝒩𝒥-derivations" and derivations in the systems of
Russell, Hilbert, and Heyting is the following: In
the latter systems true formulae are derived from a
series of "logical basic formulae" by means of a
few forms of inference. Natural deduction, however,
does not, in general, start from logical basic pro-
positions, but rather from *assumptions* (cf. examples
in §1) to which logical deductions are applied. By
means of a later inference the result is then again
made independent of the assumption.

Calculi of the former kind will be referred to as
*logistic* calculi.

**2.2.** After this preliminary remark we define the
concept of an 𝒩𝒥-*derivation* as follows:

(Examples in §4).

An 𝒩𝒥-derivation consists of formulae ordered
in tree form ([I, 3.3]).

(By demanding that the formulae are in tree
form we are deviating somewhat from the analogy
with actual reasoning. This is so, since in actual
reasoning we necessarily have (1) a linear sequence
of propositions due to the linear ordering of our
utterances, and (2) we are accustomed to applying
repeatedly a result once it has been obtained,
whereas the tree form permits only of a single use
of a derived formula. These two deviations permit
us to define the concept of a derivation in a more
convenient form and are purely external.)

The initial formulae of the derivation are
*assumption formulae*. Each of these is correlated
with precisely one 𝒟-inference figure (and in
fact occurs "above" [I, 3.5] the lower formula
of that figure, as will be explained more fully
below).

All formulae that occur below an assumption
formula, but still above the lower formula of the
𝒟-inference figure with which that assumption
formula is correlated, that assumption formula
is not included, are said to be *dependent* on the
assumption formula.

(Thus the inference makes all succeeding pro-
positions independent of the assumption which is
correlated with it.)

According to what we have said the endformula
of the derivation depends on no assumption
formula.

**2.21.** We shall now state the permissible *inference
figures*.

The inference figure schemata below are to be
understood in the following way:

We obtain an 𝒩ℐ-inference figure from one of
the schemata by replacing **A, B, C, D** by arbitrary
formulae; and **∀xFx** (**∃xFx**) by an arbitrary
formula containing ∀ or ∃ for its terminal symbol,
where **x** indicates the bound object variable
belonging to that terminal symbol; and **Fa** by the
formula obtained from **Fx** by replacing the bound
variable **x**, which it contains, by the free object
variable **a**.

(For **a** we may, for instance, take a variable
already occurring in **Fx**. For the inference figures
∀-*I* and ∃-*E*, this possibility will, however, be
excluded by the restriction on variables which
follows below, but it remains for ∀-*E* and ∃-*I*. Nor
need **x** occur at all in **Fx**, in which case **Fa** is, of
course, identical with **Fx**. — **Fa** is obviously always
a subformula of **∀xFx** (**∃xFx**), according to the
definition of a subformula in 1, 2.2.)

Symbols written in square brackets have the
following meaning: An arbitrary number (possibly
zero) of formulae of this form, all formally identical,
may be correlated with the inference figure as
assumption formulae. They must then be initial
formulae of the derivation and, moreover, occur in
branches of proofs to which the particular upper
formula of the inference figure belongs. (I.e. the
upper formula above which the square bracket
occurs in the scheme. This formula may already
itself be an assumption formula.)

The fact that there is a correlation in a derivation
between a *D*-inference figure and the related
assumption formulae must somehow be made
explicit, for example, by jointly numbering them
(cf. examples in §4).

The designations of the various inference figure
schemata: &-*I*, &-*E*, etc., stand for the following:
An inference figure formed according to the particular schema is an "introduction" (*I*) or an "elimination" (*E*) of the conjunction (&), the disjunction
(∨), the universal quantifier (∀), the existential
quantifier (∃), the implication (⊃), or of the
negation (¬). More about this in §5.

The Inference Figure Schemata:

```txt
&-I         &-E         ∨-I         ∨-E
                                   [A][B]
A   B    A & B  A & B     A      B   A ∨ B  C  C
─────    ─────  ─────   ─────  ─────  ───────────
A & B      A      B     A ∨ B  A ∨ B      C
```

```txt
∀-I        ∀-E        ∃-I        ∃-E
                                 [Fa]
Fa         ∀xFx       Fa         ∃xFx  C
------     ----       ----       --------
∀xFx       Fa         ∃xFx       C

⊃-I        ⊃-E        ¬-I        ¬-E
[A]                   [A]
B          A  A ⊃ B   F          A  ¬A     F
------     --------   ----       ------    ---
A ⊃ B      B          ¬A         F         D
```

The free object variable of a ∀-*I* or ∃-*E*,
represented by **a** in the respective schema, is called
a *proper variable*. (This, of course, presupposes that
there is such a variable, i.e., that the bound object
variable represented by **x** occurs in the formula
represented by **Fx**.)

*Restrictions on Variables*:

An 𝒩ℐ-derivation is subject to the following
restriction (for the significance of this restriction
cf. §3):

The proper variable of an ∀-*I* must not occur
in the formula represented in the schema by
∀**xFx**, nor in any assumption formula upon which
that formula depends.

The proper variable of an ∃-*E* must not occur in
the formula represented in the schema by ∃**xFx**;
nor in an upper formula represented by **C**; nor in
any assumption formula upon which that formula
depends, with the exception of the assumption
formula represented by **Fa** correlated with the
∃-*E*.

This concludes the definition of the "𝒩ℐ-
derivation."

§3.

*Intuitive Sense of* 𝒩ℐ-*Inference Figures*

We shall explain the intuitive sense of a number
of inference figure schemata and thus try to show
how the calculus in fact reflects "actual reasoning."

⊃-*I*: Expressed in words, this inference corres-
ponds to the following inference: If **B** has been
proved by means of assumption **A**, we have (this
time without the assumption): from **A** follows **B**.
(Further assumptions may, of course, have been
made and which continue to depend on them.)

∨-*E* ("Distinction of Cases"): If **A** ∨ **B** has been
proved, one can distinguish two cases: What one
first assumes is that **A** holds and derives, let us say,
**C** from it. If it is then possible to derive **C** also by
assuming that **B** holds, then **C** holds generally, i.e.,
it is no more dependent on the occurrence of **A**

∀-*I*: If **Fa** has been proved for an "arbitrary
**a**," then ∀**xFx** holds. The presupposition that **a**
is "completely arbitrary" can be expressed more
precisely as: **Fa** must not depend on any assump-
tion in which the object variable **a** occurs. And
this, again, with the obvious requirement that
*every occurrence* of **a** in **Fa** must be replaced by an **x**
in **Fx**, constitutes precisely the part of the "restric-
tions on variables" relative to the schema of the
∀-*I*.

∃-*E*: We have ∃**xFx**. We then say: Suppose **a** is
an object for which **F** holds, i.e., assume that **Fa**
holds. (It is, of course, obvious that for **a** we must
take an object variable which does not yet occur
in ∃**xFx**.) If, on this assumption, we then prove a
proposition **C** which no longer contains **a** and does
not depend on any other assumption containing
**a**, we have proved **C** independently of the assump-
tion **Fa**. We have here stated the part of the
"restrictions on variables" that concerns the ∃-*E*.
(A certain analogy exists between the ∃-*E* and the
∨-*E* since the existential quantifier is indeed the
generalization of ∨; and the universal quantifier
the generalization of &.)

┬-*E*: **A** and ¬ **A** signify a contradiction, and
this cannot obtain (law of contradiction). This is
formally expressed by the inference figure ┬-*E*,
where **F** designates "the contradiction," "the
false."

┬-*I*: (*Reductio ad absurdum*.) If we can derive any
false proposition (**F**) on an assumption **A**, then **A**
is not true, i.e., ¬ **A** holds.

The schema **F**
           **D**

If a false proposition holds, any arbitrary pro-
position also holds.

The interpretation of the remaining inference
figure schemata is straightforward.

§4.

*Representation of the three examples of §1
as NJ-Derivations*

First example (1.1):

```txt
                    1                1   Y & Z
                    X                X   ——— &-E   Y & Z
                ————— ∨-I   ————— ∨-I   Y         Z    &-E
            2   X∨Y         X∨Z       ————— &-I ————— &-I
X∨(Y & Z)  (X∨Y) & (X∨Z)        X∨Y       X∨Z
————————————————————————————————————————————— ∨-E 1
        (X∨Y) & (X∨Z)
    ——————————————————————————————— ⊃-I 2
    (X∨(Y & Z)) ⊃ ((X∨Y) & (X∨Z))
```

In this example the tree form must appear
somewhat artificial since it does not bring out the
fact that it is *after* the enunciation of X ∨ (Y & Z)
that we distinguish the cases X, Y & Z.

Second example (1.2):

```txt
                            ∀y Fay
                            ―――――  ∀-E
                             Fab        
                    2                   ∃-I
                             ∃x Fxb    ――――
        ∃x ∀y Fxy      ∀y ∃x Fxy      ∀-I
        ―――――――――      ―――――――――      ∃-E 1
           ∀y ∃x Fxy                   
                                       ⊃-I 2
    (∃x ∀y Fxy) ⊃ (∀y ∃x Fxy)
```

If we were to use *linear* ordering, then here too
the assumption of the ∃-E would quite naturally
*follow* the upper formula on the left, as was the
case in our treatment of that example in §1.

Third example (1.3):

```txt
        2                1
       ――                
       Fa    ∃-I         
      ―――――              ┐ ∃xFx
      ∃xFx               ┐      ┐-E
                   F            
                        
                   ┐ Fa  ┐-I2
                   ――――――
                        
       ∀y ┐ Fy    ∀-I
       ―――――――         
                              ⊃-I1
    (┐ ∃xFx) ⊃ (∀y ┐ Fy)
```

§5.

*Some Remarks Concerning the Calculus NJ.*
*The Calculus NK*

5.1. The calculus NJ lacks a certain formal
elegance. This has to be put against the following
advantages:

5.11. A close affinity to actual reasoning, which
had been our fundamental aim in setting up the
calculus. The calculus lends itself in particular to
the formalization of mathematical proofs.

5.12. In most cases the derivations for valid
formulae in our calculus are *shorter* than their
counterparts in logistic calculi. This is so primarily
because in logistic derivations one and the same
formula usually occurs (because of times as part
of other formulae), whereas this happens only very
rarely in the case of NJ-derivations.

5.13. The designations given to the various
inference figures (2.21) make it plain that our
calculus is remarkably *systematic*. To every logical
symbol &, ∨, ∀, ∃, ⊃, ┐ there are one or two

inference figure which "introduces" the symbol—as
the terminal symbol of a formula—and one which
"eliminates" it. The fact that the inference figures
&¬E and ∨¬I each have two forms constitutes a
trivial, purely external deviation and is of no
interest. The introductions represent, as it were, the
"definitions" of the symbols concerned, and the
eliminations are no more, in the final analysis, than
the consequences of these definitions. This fact may
be expressed as follows: In eliminating a symbol,
the formula whose terminal symbol we are dealing
with, may be used only "in the sense afforded
it by the introduction of that symbol." An example
may clarify what is meant: We were able to
introduce the formula **A ⊃ B** when there existed a
derivation of **B** from the assumption formula **A**. If
we then wished to use that formula by eliminating
the ⊃-symbol [we could, of course, also use it to
form longer formulae, e.g., (**A ⊃ B**) ∨ **C**, ∨¬I], we
could do this precisely by inferring **B** directly, once
**A** has been proved, for what **A ⊃ B** attests is just
the existence of a derivation of **B** from **A**. Note that
in saying this we need not go into the "intuitive
sense" of the ⊃-symbol.

By making these ideas more precise it should be
possible to display the *E*-inferences as single-
valued functions of their corresponding *I*-infer-
ences, on the basis of certain requirements.

5.2. It is possible to eliminate the negation from
our calculus by regarding ¬ **A** as an abbreviation
of **A⊃F**. This is permissible, since by replacing
every ¬ **A** by **A⊃F**, and thus removing all ¬-
symbols from an *NJ*-derivation, we obtain another
*NJ*-derivation (the inference figures ¬¬*I* and
¬¬*E* then become special cases of the ⊃¬*I* and the
⊃¬*E*) and vice versa: If we replace every occur-
rence of **A⊃F** by ¬**A** in an *NJ*-derivation, we
obtain another *NJ*-derivation.

The inference figure schema **D̄** occupies a special
place among the schemata: It does not belong to a
logical symbol, but to the propositional symbol **F**.
5.3. The "*law of the excluded middle*" and the
*calculus NK*.

From the calculus *NJ* we obtain a complete
classical calculus *NK* by adding the "law of the
excluded middle" (*tertium non datur*), i.e.: As
initial formulae of a derivation we now also allow
in addition to the assumption formulae, "basic
formulae" of the form **A** ∨ ¬**A**, where **A** is to be
replaced by an arbitrary formula.

Actually, instead of the law of the excluded
middle, in a purely exterior way, a special position,

and we have done this because we considered that
formulation the "most natural." It would be
perfectly feasible to introduce a new inference

figure schema, say ¬¬A (a schema analogous to
                    A
the one formed by Hilbert and Heyting) in place
of the basic formula schema A ∨ ¬A. However,
such a schema still falls outside the framework of
the 𝒩𝒥-inference figures, because it represents a
new elimination of the negation whose admissi-
bility does not follow at all from our method of
introducing the ¬-symbol by the ¬-𝐼.

## SECTION III.

**DEDUCTIVE CALCULI LJ, LK AND THE HAUPTSATZ**

### §1.

*The Calculi LJ and LK*
*(Logistic Intuitionist and Classical Calculus)*

**1.1.** Preliminary remarks concerning the con-
struction of the calculi *LJ* and *LK*.

What we want to do is to formulate a deductive
calculus (for predicate logic) which is "logistic" on
the one hand, i.e., in which the derivations do not,
as in the calculus 𝒩𝒥, contain assumption formulae,
and which, on the other hand, takes over from the
calculus 𝒩𝒥 the division of the forms of inference
into introductions and eliminations of the various
logical symbols.

The most obvious method of converting an 𝒩𝒥-
derivation into a logistic one is this: We replace a
derivation **B**, which depends on the assumption
formulae **A**₁, . . . , **A**ₙ, by the new formula (**A**₁&
. . . &**A**ₙ) ⊃ **B**. This we do in all *D*-formulae.

We thus obtain formulae which are already valid
*in themselves*, i.e., whose truth is no longer *conditional*
on the truth of certain assumption formulae. This
procedure, however, introduces the new logical
symbols & and ⊃, necessitating additional
inference figures for & and ⊃, and thus upsets the
systematic character of our method of introducing
and eliminating symbols. For this reason we have
introduced the concept of a *sequent* (I, 2.3).
Instead of the formula (**A**₁& . . . &**A**ₙ) ⊃**B**, e.g.,
we therefore write the sequent

**A**₁, . . . , **A**ₙ —> **B**

The sequent does not distinguish itself from the
above formula in its intuitive meaning, but only in
its formal structure (cf. I, 2.4).

Even now new inference figures are required that
cannot be integrated into our system of introduc-
tions and eliminations; but we have the advantage
of being able to reserve them special places within
our system, since they no longer refer to logical
symbols, but merely to the structure of the formulae.
We therefore call these "structural inference
figures," and the others "operational inference
figures."

In the *classical* calculus 𝒩𝒦 the law of the
excluded middle occupied a special place among
the forms of inference (II, 5.3), because it could
not be integrated into our system of introductions
and eliminations. In the classical logistic calculus
ℒ𝒦 to be presented below, that peculiarity is
removed. What makes this possible is that we
admit into our system sequents with *several* formulae
in the succedent, whereas the indicated transition
from the calculus 𝒩𝒥 has resulted only in sequents
with *one* formula in the succedent. (For the
intuitive meaning of the general sequents cf. I, 2.4.)
The symmetry thus obtained is more suited to
classical logic. On the other hand, the restriction
to at most one formula in the succedent will be
retained for the intuitionist calculus ℒ𝒥. (Cf. below
—An empty succedent means the same as if 𝔽 stood
in the succedent.)

We have thus outlined a number of points that
underlie the construction of the calculi that follow.
Their form is largely determined, however, by
considerations connected with the "*Hauptsatz*"
(§2) whose proof follows later. That form cannot
therefore be justified more fully at this stage.

1.2. We now define the concepts of a "ℒ𝒦–
derivation" and a "ℒ𝒥–derivation" as follows:

An ℒ𝒥– or ℒ𝒦–derivation consists of sequents
arranged in tree form (I, 3.3).

The *initial sequents* of the derivation are basic
sequents of the form

**D ⟶ D,**

where **D** may be an arbitrary formula.

Each *inference figure* of the derivation results
from one of the schemata below by a substitution of
the following kind (cf. II, 2.21):

Replace **A, B, D, E** by arbitrary formulae; for
∀ 𝔵𝔉𝔵 (∃𝔵𝔉𝔵) put an arbitrary formula having
∀ (∃) for its terminal symbol, where 𝔵 designates
the associated bound object variable; for **F𝔞**
put that formula which is obtained from **F𝔵** by
replacing every occurrence of the bound object
variable 𝔵 by the free object variable 𝔞.

For Γ, Δ, Θ, Λ put arbitrary (possibly empty)
sequences of formulae separated by commas.

The following restriction is furthermore placed
on *LJ*-*inference figures* (this is the *only* respect in
which the concepts of a *LJ*– and a *LK*–derivation
differ):

"In the succedent of each *D*–sequent no more
than one *S*–formula is permissible."

The designations of the various schemata for
operational inference figures &–*IS*, &–*IA*, etc.,
are intended to mean: An inference figure formed
according to the schema is an introduction (*I*) in
the succedent (*S*) or antecedent (*A*) of the con-
junction (&), the disjunction (∨), the universal
quantifier (∀), the existential quantifier (∃), the
negation (¬), or the implication(⊃).

## The Inference Figure Schemata

**1.21. Schemata for structural inference figures:**
Thinning:

     in the antecedent       in the succedent
          Γ ⟶ Θ                   Γ ⟶ Θ
       ___________              ___________   ;
       𝐃, Γ ⟶ Θ'                Γ ⟶ Θ, 𝐃'

Contraction:

     in the antecedent       in the succedent
       𝐃, 𝐃, Γ ⟶ Θ              Γ ⟶ Θ, 𝐃, 𝐃
       ___________              ___________   ;
         𝐃, Γ ⟶ Θ'              Γ ⟶ Θ, 𝐃

Interchange:

     in the antecedent       in the succedent
     Δ, 𝐃, 𝐄, Γ ⟶ Θ            Γ ⟶ Θ, 𝐄, 𝐃, Δ
     _______________            _______________  ;
     Δ, 𝐄, 𝐃, Γ ⟶ Θ'           Γ ⟶ Θ, 𝐃, 𝐄, Δ

Cut:
          Γ ⟶ Θ, 𝐃   𝐃, Δ ⟶ Λ
          _____________________
                Γ, Δ ⟶ Θ, Λ

**1.22. Schemata for operational inference figures:**

&–*IS*:  Γ ⟶ Θ, 𝐀   Γ ⟶ Θ, 𝐁
        _____________________  ,
           Γ ⟶ Θ, 𝐀 & 𝐁

&–*IA*:     𝐀, Γ ⟶ Θ           𝐁, Γ ⟶ Θ
        _______________    _______________  ,
        𝐀 & 𝐁, Γ ⟶ Θ    𝐀 & 𝐁, Γ ⟶ Θ

∨–*IS*:  𝐀, Γ ⟶ Θ   𝐁, Γ ⟶ Θ
        _____________________  ,
           𝐀 ∨ 𝐁, Γ ⟶ Θ

∨–*IA*:  Γ ⟶ Θ, 𝐀           Γ ⟶ Θ, 𝐁
        _______________    _______________  ,
        Γ ⟶ Θ, 𝐀 ∨ 𝐁    Γ ⟶ Θ, 𝐀 ∨ 𝐁

∀-*IS*: Γ ⟶ Θ, **Fa** / Γ ⟶ Θ, ∀**xFx**'

∃-*IA*: **Fa**, Γ ⟶ Θ / ∃**xFx**, Γ ⟶ Θ'

*Restrictions on Variables:* The object variable in
the last two schemata, which is designated by **a** and
is called the *proper variable* of the ∀-*IS* (∃-*IA*), must
not occur in the lower sequent of the inference
figure (i.e., not in Γ, Θ, and **Fx**).

∀-*IA*: **Fa**, Γ ⟶ Θ / ∀**xFx**, Γ ⟶ Θ'

¬-*IS*: A, Γ ⟶ Θ / Γ ⟶ Θ, ¬ A'

∃-*IS*: Γ ⟶ Θ, **Fa** / Γ ⟶ Θ, ∃**xFx**'

¬-*IA*: Γ ⟶ Θ, A / ¬ A, Γ ⟶ Θ'

⊃-*IS*: A, Γ ⟶ Θ, B / Γ ⟶ Θ, A ⊃ B'

⊃-*IA*: Γ ⟶ Θ, A    B, Δ ⟶ Λ / A ⊃ B, Γ, Δ ⟶ Θ, Λ

1.3. Example of an *LJ*-derivation (following
II, 4.3):

```txt
                    ∃xFx ⟶ ∃xFx
Fa ⟶ Fa                            ¬-IA
─────────── ∃-IS  ¬ ∃xFx, ∃xFx ⟶ 
Fa ⟶ ∃xFx         ─────────────────── Interchange
                  ∃xFx, ¬ ∃xFx ⟶
                  ────────────────── Cut
              Fa, ¬ ∃xFx ⟶
              ────────────────── ¬-IS
              ¬ ∃xFx ⟶ ¬ Fa
              ────────────────── ∀-IS
              ¬ ∃xFx ⟶ ∀y ¬Fy
              ────────────────── ⊃-IS
              ⟶(¬∃xFx)⊃(∀y ¬Fy)
```

1.4. Example of an *LK*-derivation (derivation
of the "law of the excluded middle"):

```txt
A⟶A
────────── ¬-IS
⟶A, ¬ A
────────── ∨-IS
⟶A, A ∨ ¬ A
────────────── Interchange
⟶A ∨ ¬ A, A
────────────────────── ∨-IS
⟶A ∨ ¬ A, A ∨ ¬ A
─────────────────── Contraction
⟶A ∨ ¬ A
```

§2.

## Some Remarks Concerning the Calculi LJ and LK

### The Hauptsatz

(We shall make no further use, in this paper, of
remarks 2.1 to 2.3.)

2.1. The schemata are not all mutually inde-
pendent, i.e., certain schemata could be eliminated
with the help of the remaining ones. Yet if they
were left out, the "*Hauptsatz*" would no longer be
valid.

2.2. In general, we could *simplify* the calculi in
various respects if we attached no importance to
the *Hauptsatz*. To indicate this briefly: the infer-
ence figures &–IS, ∨–IA, &–IA, ∨–IS, ∀–IA,
∃–IS, ⊃–IS, ¬–IA, and ∀–IA in the calculus *LK*
could be replaced by the basic schemata according to
the following schemata:

A, B⟶A&B   A ∨ B⟶A, B   A&B⟶A
A&B⟶B   A⟶A ∨ B   B⟶A ∨ B   ∀xFx⟶Fa
Fa⟶∃xFx   ⊃A, ¬A   (law of the excluded
middle)

¬A, A⟶ (law of contradiction), A ⊃ B, A⟶B.

These basic sequents and our inference figures
may easily be shown to be equivalent.

The same possibility exists for the calculus *LJ*,
with the exception of the inference figures ∨–IA
and ¬–IA, since *LJ*-D-sequents may not in fact
contain two *S*-formulae in the succedent (cf. V,
§5).

2.3. The distinction between *intuitionist* and
*classical* logic is, externally, of a quite different
nature in the calculi *LJ* and *LK* from that in the
calculi *NJ* and *NK*. In the case of the latter, the
distinction rests on the inclusion or exclusion of the
law of the excluded middle, whereas for the
calculi *LJ* and *LK* the difference is characterized by
the restrictions on the succedent. (The fact that
both distinctions are equivalent will become
evident as a result of the equivalence proofs in
Section V for all calculi discussed in this paper.)

2.4. If ⊃–IS and the ⊃–IA are excluded, the
calculus *LK* is *dual* in the following sense. If we
reverse all sequents of an *LK*-derivation (in which
the ⊃–symbols does not occur), i.e., if for A₁, . . . ,
Aₘ⟶B₁, . . . , Bₙ we put Bₙ, . . . , B₁⟶Aₘ, . . . ,
A₁; and if we exchange, in inference figures with
two upper sequents, the right and left-hand upper
sequents, including their derivations, and also
exchange the inference of & by ∨, ∀ by ∃, ∨ by
&, and ∃ by ∀ (in the case of & and ∨ we also

have to change the respective scope of the symbols,
e.g., for B ∨ A we have to put A&B), then another
*LK*-derivation results.

This can be seen at once from the schemata.
(Special care was taken to order them in such a way
as to bring out this relation).

(Cf. H-A's duality principle, p. 62).

2.41. In any case, the ⊃-symbol may, in a well-
known manner, be eliminated from the calculus
𝒩𝒦, by regarding A⊃B as an abbreviation for
(¬A) ∨ B. It may easily be shown that the
schemata for the ⊃-𝒥 and the ⊃-𝒮ℐ can then be
replaced by the schemata for ∨ and ¬.

The calculus 𝒩𝒥 has no corresponding property.

2.5. The most important fact for us with regard
to the calculi 𝒵𝒥 and 𝒵𝒦 is the following:

**Hauptsatz.** Every 𝒵𝒥- or 𝒵𝒦-derivation can be
transformed into an 𝒵𝒥- or 𝒵𝒦-derivation that has
the same endsequent and in which the inference
figure termed a "cut" does not occur.

2.51. The proof follows in §3.

In order to give greater clarity to the meaning of
the *Hauptsatz*, we prove a simple corollary (2.513).

For this purpose we introduce a number of
expressions (which will be needed frequently later
on) relating to operational inference figures.

2.511. That 𝒮-formula which contains the logical
symbol in its schema will be called the *principal
formula* of an inference figure.

For the &-𝒮ℐ and the &-𝒮𝒜 this is simply the
𝒮-formula of the form A&B; for the ∨-𝒮ℐ and the
∨-𝒮𝒜 it is A ∨ B; for the ∀-𝒮ℐ and the ∀-𝒮𝒜 it is
∀xℱx; for the ∃-𝒮ℐ and the ∃-𝒮𝒜 it is ∃xℱx; for the
¬-𝒮ℐ and the ¬-𝒮𝒜 it is ¬A; and for the ⊃-𝒮ℐ
and the ⊃-𝒮𝒜 it is A⊃B.

The 𝒮-formulae designated by A, B, ℱa in the
schemata we call *side formulae* of their correspond-
ing inference figures.

They are always subformulae of the principal
formula (according to the definition of a subformula
in I, 2.2).

2.512. We can now easily read off the following
facts from the inference figure schemata: A
principal formula occurs always in the lower
sequent, a side formula always in the upper
sequent or in one upper sequent.

In the case of a formula occurring as an 𝒮-
formula in an upper sequent of an arbitrary
inference figure without being a side formula or the
D of a cut, it occurs also in the lower sequent as an
𝒮-formula.

These two facts entail the following:

If anywhere in an 𝒵𝒥- or 𝒵𝒦-derivation a

formula occurs as an *S*-formula, and if we trace the
branch of the derivation from the formula con-
cerned up to the endsequent, the formula can only
then vanish from that branch if it is the **D** of a cut
or the side formula of an operational inference
figure. In the latter case, however, there appears
in the next sequent, the *principal formula* of the
inference figure of which our side formula is a
subformula. To that principal formula we can
then, continuing downwards, apply the same
consideration, and so on. Thus we obtain the
following corollary:

2.513. *Corollary of the Hauptsatz (subformula
property)*: In an *LJ*- or *LK*-derivation without
cuts, all occurring *D*-*S*-formulae are subformulae of
the *S*-formula that occurs in the endsequent.

2.514. Intuitively speaking, these properties of
derivations without cuts may be expressed as
follows: The *S*-formulae become larger as we
descend lower down in the derivation, never
shorter. The final result is, as it were, gradually
built up from its constituent elements. The proof
represented by the derivation is not roundabout
in that it contains only concepts which recur in the
final result (cf. the synopsis at the beginning of this
paper).

*Example*: The derivation given above (1.3) for
⟶(⬜∃x𝐅x) ⊃ (∀ 𝐲 ⬜𝐅𝐲) may be written without
a cut as follows:

```txt
                     Fa ⟶ Fa
           Fa ⟶ ∃xFx  ∃-IS
      ⬜∃xFx, Fa ⟶     ⬜-IA
    Fa, ⬜∃xFx ⟶       Interchange
```

etc., as above.

§3.

*Proof of the Hauptsatz*

The *Hauptsatz* runs as follows:

Every *LJ*- or *LK*-derivation can be transformed
into another *LJ*- or *LK*-derivation with the same
endsequent, in which no cuts occur.

3.1. *Proof of the Hauptsatz for LK-derivations.*

We introduce a new inference figure (in order to
facilitate the proof) that constitutes a modified
form of the cut, and which we call a *mix*.

The schema of that figure runs as follows:

```txt
      Γ ⟶ Θ   Δ ⟶ Λ
      Γ, Δ* ⟶ Θ*, Λ
```

In order to obtain an inference figure from this
schema, Θ and Δ must be replaced by sequences of

formulae, separated by commas, in each of which
occurs at least once (as a member of the sequence)
a formula of the form M, called the "mix formula";
and *Θ*⁺ and *Δ** must be replaced by the same
sequences of formulae, save that all formulae of the
form M occurring as members of the sequence are
omitted. (M is an arbitrary formula.) *Γ* and *Λ* must
be replaced, as in the other schemata, by arbitrary
(possibly empty) sequences of formulae, separated
by commas.

Example of a mix:

```txt
A —→ B, ¬A   B ∨ C, B, B, D, B —→
        A, B ∨ C, D —→ ¬A
```

*B* is the mix formula.

We can prove that every cut may be trans-
formed into a mix by means of a number of
thinnings and interchanges. (Conversely, every mix
may be transformed into a cut by means of a certain
number of preceding interchanges and contrac-
tions, though we do not use this fact.)

In the following we shall consider only deriva-
tions in which no cuts occur. (Such may
contain mixes instead.

Since derivations in the old sense may be
transformed into derivations of the new kind, it
suffices, for the proof of the *Hauptsatz*, to show that
a derivation of the new type may be transformed
into a derivation with no mix.

Furthermore, the following lemma is already
sufficient:

*Lemma*: Any derivation with a mix for its
lowest inference figure, and not containing any
other mix, may be transformed into a derivation
(with the same endsequent) in which no mix
occurs.

From this the complete theorem easily follows:

In an arbitrary derivation consider a mix above
whose lower sequent no further mix occurs. The
derivation for this lower sequent is then of the kind
mentioned in the lemma, i.e., it may be transformed
in such a way that it no longer contains a mix. In
doing so, the rest of the derivation remains
unchanged. This operation is then repeated until
every mix has been completely been eliminated.

It now remains for us to establish the *proof of the
lemma*. (This proof extends into 3.2 incl.)

We have to consider a derivation whose lowest
inference figure is a mix and which contains no
other mix besides.

The length of the mix formula will be called the
"grade of the derivation" (defined in I, 2.2).

We shall call "rank of the derivation" the sum of
its rank on the left and its rank on the right. These
two terms are defined as follows:

The left rank is the greatest number of sequents
connected on a branch such that the last sequent is
the *left-hand* upper sequent of the mix, where each
formula of the branch contains the mix formula in
the *succedent*.

The right rank is (correspondingly) the greatest
number of sequents connected on a branch whose
lowest sequent is the *right-hand* upper sequent of the
mix, and each formula of the branch contains the
mix formula in the *antecedent*.

The lowest possible rank is evidently 2.

To prove the lemma we perform two complete
inductions, one according to the grade γ, the
other according to the rank ρ of the derivation,
i.e., we prove the theorem for the derivation of
grade γ, assuming it to hold for derivations of a
lower grade (in so far as there are such derivations,
i.e., as long as γ is not equal to zero), supposing,
therefore, that derivations of a lower grade may
already be transformed into derivations not
containing a mix.

Furthermore, we shall begin by considering the
case where the rank ρ of the derivation equals 2
(3.11), and after that the case of ρ > 2 (3.12),
where we assume that the theorem already holds
for derivations of the same grade, but of a lower
rank.

In the following bold-face capital letters will
generally serve as syntactic variables for *formulae*,
and Greek capital letters as syntactic variables for
(possibly empty) *sequences of formulae*.

In transforming derivations, we shall occasionally
meet "identical inference figures," i.e., inference
figures with the same upper and lower sequent.
Since we have not admitted such figures in our
calculus, they must be eliminated as soon as they
occur; this is trivially possible by omitting one of
the two sequents.

The mix formula of the mix that occurs at the
end of the derivation is designated by **M**. It is of
grade γ.

3.10. *Re-designating of free object variables* in
preparation for the transformation of derivations.

We wish to obtain a derivation that has the
following properties:

3.101. For every ∀-IS (∃-IA) it holds that:
Its proper variable occurs in the derivation only
in sequents *above* the lower sequent of the ∀-IS
(∃-IA) and does not occur as a proper variable of
any other ∀-IS (∃-IA).

3.102. This is achieved by re-designating the free
object variables in the following way:

We take a ∀–*IS* (∃–*IA*) above whose lower
sequent either no further inference figures of this
kind occur, or if they do, they have already been
dealt with in a way to be outlined.

In all sequents above the lower sequent of this
inference figure we replace the proper variables by
one and the same free object variable which, so
far, has not yet occurred in the derivation. This
obviously leaves the validity of the ∀–*IS* (∃–*IA*)
as such unchanged. (The proper variables did in
fact not occur in its lower sequent.) Furthermore
the remainder of the derivation remains correct, as
is shown by the immediately following lemma:

By applying this method systematically to every
single ∀–*IS* and ∃–*IA*, the derivation thus remains
correct throughout and at the conclusion obviously
has the desired property (3.101). Furthermore, as
was essential, the grade and rank of the derivation
as well as its endsequent have remained unaltered.

3.103. Now we give the still outstanding proof of
the following *lemma*. (It is enunciated in a some-
what more general form than is immediately
necessary, since we shall have to apply it again
later on (3.113.33).)

"An *LK*-basic sequent or inference figure turns into
a basic sequent or inference figure of the same
kind, if we replace a free object variable, which is *not
the proper variable* of the inference figure, in all its
occurrences in the basic sequent or inference figure, by
one and the same free object variable, provided again
that that is *not the proper variable* of the inference
figure."

This holds trivially except for the ∀–*IS*, the
∀–*IA*, the ∃–*IS* and the ∃–*IA*. Yet even here there
is no cause for concern: the restrictions on variables
are not violated, since we may neither substitute
nor replace the proper variable. (This is the reason
why both restrictions on variables are necessary.)
Furthermore, the formula resulting from **Fa** is still
obtained by substituting a for x in the formula
resulting from **Fx**.

Having prepared the way (3.10), we now
proceed to the actual transformation of the
derivation which serves to eliminate the mix
occurring in it.

As already mentioned, we distinguish two cases:
ρ = 2 (3.11) and ρ > 2 (3.12).

3.11. Suppose ρ = 2.

We distinguish between a number of particular
cases of which we specify only the first (3.111)

are especially simple in that they allow the mix to be
immediately eliminated. The other cases (3.113.3)
are the most important since their consideration
brings out the basic idea behind the whole trans-
formation. Here we use the induction hypothesis
with respect to γ, i.e., we reduce each one of the
cases to transformed derivations of a lower grade.

3.111. Suppose the left-hand upper sequent of the
mix at the end of the derivation is a *basic sequent*.
The mix then reads:

```txt
     M —→ M   Δ —→ Λ
     ——————————————————
       M, Δ* —→ Λ
```

which is transformed into:

```txt
     Δ —→ Λ       possibly several interchanges
   ——————————     and contractions.
   M, Δ* —→ Λ
```

That part of the derivation which is above
*Δ —→ Λ* remains the same, and we thus already
have a derivation without a mix.

3.112. Suppose the right-hand upper sequent of
the mix is a *basic sequent*. The treatment of this case
is symmetric to that of the previous one. We have
only to repeat the two schemata as follows:

3.113. Suppose that neither the left- nor the
right-hand upper sequent of the mix is a basic
sequent. Then both are *lower sequents of inference
figures* since ρ = 2, and the right and left rank both
equal 1, i.e. In the sequents directly above the
left-hand upper sequent of the mix the mix formula
**M** does not occur in the *succedent*; in the sequents
directly above the *right-hand* upper sequent **M** does
not occur in the *antecedent*.

Now the following holds generally: If a formula
occurs in the antecedent (succedent) of the lower
sequent of an inference figure, it is either a principal
formula or the **D** of a thinning, or else it also
occurs in the antecedent (succedent) in at least one
upper sequent of the inference figure.

This is true immediately by looking at the
inference figure schemata (1.21, 1.22).

If we now consider the assumptions of the
following three cases, we see at once that they
exhaust all the possibilities that exist within case
3.113.

3.113.1. Suppose the left-hand upper sequent of
the mix is the lower sequent of a *thinning*. Then the
conclusion of the derivation runs:

```txt
         Γ —→ Θ
    ———————————————————
    Γ —→ Θ, M   Δ —→ Λ
    ———————————————————
       Γ, Δ* —→ Θ, Λ
```

This is transformed into:

```txt
     Γ → Θ       possibly several thinnings
───────────────── 
Γ, Δ* → Θ, Δ     and interchanges.
```

That part of the derivation which occurs above
Δ → Δ disappears.

3.113.2. Suppose the right-hand upper sequent of
the mix is the lower sequent of a thinning. This
case can be dealt with symmetrically to the
previous one.

3.113.3. The mix formula **M** occurs both in the
succedent of the left-hand upper sequent and in
the antecedent of the right-hand upper sequent
solely as the *principal formula* of one of the opera-
tional inference figures.

Depending on whether the terminal symbol of **M**
is &, ∨, ⊃ or ¬, we distinguish the cases
3.113.31 to 3.113.36 (a formula without logical
symbols cannot be a principal formula).

3.113.31. Suppose the terminal symbol of **M** is
&. In that case the end of the derivation runs:

```txt
Γ₁→ Θ₁, A    Γ₁→ Θ₁, B         A, Γ₂→ Θ₂
────────────────────── &-IS  ────────────── &-IA
    Γ₁→ Θ₁, A & B           A & B, Γ₂→ Θ₂
    ───────────────────────────────────── mix
              Γ₁, Γ₂→ Θ₁, Θ₂
```

(and correspondingly for the other form of the
&-IA, treated analogously.)

We transform it into:

```txt
Γ₁→ Θ₁, A    A, Γ₂→ Θ₂
──────────────────────── mix
    Γ₁, Γ₂*→ Θ₁*, Θ₂    possibly several thinnings
    ─────────────────────
    Γ₁, Γ₂ → Θ₁,  Θ₂    and interchanges.
```

We can now apply the induction hypothesis with
respect to γ to that part of the derivation whose
lowest sequent is Γ₁, Γ₂*→ Θ₁*, Θ₂, because it has
a lower grade than γ. (A obviously contains fewer
logical symbols than A&B.) This means that the
whole derivation may be transformed into one with
no mix.

3.113.32. Suppose the terminal symbol of **M** is ∨.
This case is to be dealt with symmetrically to the
previous one.

3.113.33. Suppose the terminal symbol of **M** is
⊃. Then the end of the derivation runs:

```txt
Γ₁→ Θ₁,  Fa              Fb, Γ₂→ Θ₂
─────────── ∀-IS    ──────────────── ∀-IA
Γ₁→ Θ₁, ∀xFx       ∀xFx, Γ₂→ Θ₂
          ─────────────────────── mix.
            Γ₁, Γ₂→ Θ₁, Θ₂
```

This is transformed into:

```txt
Γ₁⟶ Θ₁, Fb    Fb, Γ₂⟶ Θ₂
─────────────────────────── mix
Γ₁, Γ₂*⟶ Θ₁*, Θ₂ possibly several thinnings
─────────────────── and interchanges.
Γ₁, Γ₂⟶ Θ₁, Θ₂
```

Above the left-hand upper sequent of the mix,
Γ₁⟶ Θ₁, **Fb**, we write the same part of the
derivation which previously occurred above
Γ₁⟶ Θ₁, **Fa**, yet having replaced every occurrence
of the free variable **a** by **b**. It follows therefore,
from the lemma 3.103, together with 3.101, that in
performing this operation the part of the deriva-
tion *above* Γ₁⟶ Θ₁, **Fb** has again become a
correct part of the derivation. (By virtue of 3.101
neither **a** nor **b** can be the proper variable of an
inference figure occurring in that part of the
derivation.) The same consideration may be
applied to that part of the derivation which
*includes* the sequent Γ₁⟶ Θ₁, **Fb**, since it too
results from Γ₁⟶ Θ₁, **Fa** by substitution of **b** for
**a**. It is now in fact clear that by virtue of the
occurring free variables for **x**–*IS*, **a** could have
occurred neither in Γ₁ and Θ₁, nor in **Fx**. Further-
more, **Fa** results from **Fx** by substituting **a** for **x**,
and **Fb** from **Fx** by substituting **b** for **x**. This is
why **Fb** results from **Fa** by substituting **b** for **a**.

The mix formula **Fb** in the new derivation has a
lower grade than γ. Therefore, according to the
induction hypothesis, the mix may be eliminated.

3.113.34. Suppose the terminal symbol of **M** is
∃. This case is resolved symmetrically to the
previous one.

3.113.35. Suppose the terminal symbol of **M** is
⊃. Then the end of the derivation runs:

```txt
A, Γ₁⟶Θ₁                    Γ₂⟶Θ₂, A
───────────⊃A  ⊃IS  ⊃A, Γ₂⟶Θ₂        ⊃IA
Γ₁⟶Θ₁, ⊃A       ─────────────────────────
                 Γ₁, Γ₂⟶Θ₁, Θ₂            mix.
```

This is transformed into:

```txt
Γ₂⟶ Θ₂, A    A, Γ₁⟶ Θ₁
───────────────────────── mix
Γ₂, Γ₁*⟶ Θ₂*, Θ₁ possibly several inter-
───────────────────── changes and thinnings.
Γ₁, Γ₂⟶ Θ₁, Θ₂
```

The new mix may be eliminated by virtue of the
induction hypothesis.

3.113.36. Suppose the terminal symbol of **M** is
⊃. Then the end of the derivation runs:

```
A, Γ₁ ⟶ Θ₁, B            Γ ⟶ Θ, A   B, Δ ⟶ Δ
—————————————— ⊃-IS   ———————————————————— ⊃-IA
Γ₁ ⟶ Θ₁, A ⊃ B        A ⊃ B, Γ, Δ ⟶ Θ, Δ
           ————————————————————————— mix
              Γ₁, Γ, Δ ⟶ Θ₁, Θ, Δ
```

This is transformed into:

```
      A, Γ₁ ⟶ Θ₁, B   B, Δ ⟶ Δ
Γ ⟶ Θ, A    A, Γ₁, Δ* ⟶ Θ₁*, Δ  mix
——————————————————————————————— mix
    Γ, Γ₁*, Δ** ⟶ Θ*, Θ₁*, Δ
    ————————————————————————— possibly several inter-
       Γ₁, Γ, Δ ⟶ Θ₁, Θ, Δ    changes and thinnings
```

(The asterisks are, of course, intended to be
understood as follows: Δ* and Θ* result from Δ and
Θ₁ by omitting all S-formulae of the form B; Γ₁*,
Δ** and Θ* result from Γ₁, Δ* and Θ by omitting
all S-formulae of the form A.)

Now we have two mixes, but both mix formulae
are of a lower grade than γ. With the application of the
induction hypothesis to the upper mix (i.e., to that
part of the derivation whose lowest figure is it).
Thus the upper mix may be eliminated. We can
then also eliminate the lower mix.

3.12. Suppose ρ > 2.

To begin with, we distinguish two main cases:
First case: The right rank is greater than 1 (3.121).
Second case: The right rank is equal to 1 and the
left rank is therefore greater than 1 (3.122). The
second case may essentially be dealt with sym-
metrically to the first.

3.121. Suppose the right rank is greater than 1.

I.e.: The right-hand upper sequent of the mix is
the lower sequent of an inference figure, let us call
it If, and M occurs in the antecedent of at least one
upper sequent of If.

The basic idea behind the transformation procedure
is the following:

In the case of ρ = 2, we generally reduced the
derivation to one of a lower grade. Now, however,
we shall proceed to reduce the derivation to one
of the same grade, but of a lower rank, in order to be
able to use the induction hypothesis with respect
to ρ.

The only exception is the first case, 3.121.1,
where the mix may at once be altogether elimin-
ated.

In the remaining cases the reduction to deri-
vations of a lower rank is achieved in the follow-
ing way: The mix is, as it were, moved up one level
within the derivation, beyond the inference figure
If. (Case 3.121.231, for example, illustrates this
point particularly well.) To speak more precisely,
we replace the inference figure for the mix (which
from now on will be designated by Π ⟶ Σ), at

present occurring beside the *lower sequent* of **If**, is
instead written next to the *upper sequents* of **If**. These
now become upper sequents of new mixes. The
lower sequents of these mixes are now used as
upper sequents of a new inference figure that takes
the place of **If**. This new inference figure gives us
back either directly, or after having added further
inference figures, to the original endsequent. Each
new mix obviously has a rank smaller than *ρ*,
since the left rank remains unchanged and the
right rank is diminished by at least 1.

In the strict application of this basic idea special
circumstances still arise which make it necessary to
distinguish the corresponding cases and to deal
with them separately.

3.121.1. Suppose **M** occurs in the antecedent of
the left-hand upper sequent of the mix. The end of
the derivation runs:

```txt
     Π ⟶ Σ   Δ ⟶ Λ
     ———————————————— thus M occurs in Π.
     Π, Δ*⟶ Σ*, Λ
```

This is transformed into:

```txt
     Δ ⟶ Λ        possibly several thinnings,
     ——————————————— contractions and interchanges.
     Π, Δ*⟶ Σ*, Λ
```

3.121.2. Suppose **M** does not occur in the ante-
cedent of the left-hand upper sequent of the mix.
(This assumption is used for the first time in
3.121.222.)

3.121.21. Suppose **If** is a thinning, contraction,
or interchange in the *antecedent*. Then the end of the
derivation runs:

```txt
                    Ψ ⟶ Θ
     Π ⟶ Σ         Ξ ⟶ Θ  If
     ——————————————————————— mix.
     Π, Ξ*⟶ Σ*, Θ
```

This is transformed into:

```txt
Π ⟶ Σ   Ψ ⟶ Θ
————————————————— mix
Π, Ψ* ⟶ Σ*, Θ
Ψ*, Π ⟶ Σ*, Θ possibly several interchanges
————————————————— §
Ξ*, Π ⟶ Σ*, Θ
————————————————— 
Π, Ξ* ⟶ Σ*, Θ possibly several interchanges
```

The inference figure marked § is of the same kind
as **If**, in so far as the *S*-formulae designated in the
schema of **If** (in A121) by **D** and **E**, were not equal
to **M**. If **D** or **E** is equal to **M**, then the corresponding
inference figure (**Ψ** equals **Ξ***).

The derivation for the lower sequent of the new
mix has the same left rank as the old derivation,
whereas its right rank is lower by 1. Thus the mix
may be completely eliminated by virtue of the
induction hypothesis.

3.121.22. Suppose **If** is an inference figure with
*one* upper sequent, but not containing a thinning,
contraction, or interchange in the antecedent.
Then the end of the derivation runs:

```txt
           Ψ, Γ ⟶ Ω₁
                      If
      Π ⟶ Σ   Ξ, Γ ⟶ Ω₂
      ――――――――――――――――――― mix.
      Π, Ξ*, Γ* ⟶ Σ*, Ω₂
```

Here we have comprised in Γ the same *S*-
formulae that are designated by *Γ* in the schema of
the inference figure (p. 303). Hence Ψ may be
empty or consist of a side formula of the inference
figure, and Ξ may be empty or consist of the
principal formula of the inference figure.

First of all, the end of the derivation is trans-
formed into:

```txt
Π ⟶ Σ    Ψ, Γ ⟶ Ω₁
―――――――――――――――――――― mix
Π,Ψ*, Γ* ⟶ Σ*, Ω₁
―――――――――――――――――― possibly several inter-
Ψ, Γ*, Π ⟶ Σ*, Ω₁  changes and thinnings
――――――――――――――――――
Ξ, Γ*, Π ⟶ Σ*, Ω₂
```

The lowest inference is obviously an inference
figure of the same kind as **If** (taking Γ*, Π as the
Γ of the inference figure, and including Σ* in the Θ
of the inference figure).

We must only be careful not to violate the
restrictions on variables (if **If** is a ∀-*IS* or ∃-*IA*):
Any such violation is precluded by 3.101, which
asserts that a proper variable that may have
occurred in **If** cannot have occurred in Π and Σ.

The mix may be eliminated from the new
derivation by virtue of the induction hypothesis.

We therefore obtain a derivation with no mix
and which is terminated by the following inference
figure:

```txt
Ψ, Γ*, Π ⟶ Σ*, Ω₁
――――――――――――――――――
Ξ, Γ*, Π ⟶ Σ*, Ω₂
```

In general, the endsequent is not yet of the form
aimed at.

Hence we proceed as follows:

3.121.221. Suppose Ξ does not contain **M**.

In that case we perform a series of inter-
changes, if necessary, and obtain the endsequent of
the original derivation.

3.121.222. Suppose 𝔖 contains **M**. Then 𝔖 is
the principal formula of **If** and is equal to **M**. We
then add:

```txt
Π ⟶ Σ      M, Γ*, Π ⟶ Σ*, Ω₂
─────────────────────────────── mix
    Π, Γ*, Π* ⟶ Σ*, Σ*, Ω₂
─────────────────────────── possibly several
        Π, Γ* ⟶ Σ*, Ω₂      contractions and
                             interchanges
```

Once again, this is the endsequent of the
original derivation.

(Above Π ⟶ Σ we once again write the
derivation associated with it.)

Thus we have another mix in the derivation. The
left rank of this additional mix is the same as that of the
original derivation. The right rank is now equal to
1. This is so because directly above the right-hand
upper sequent occurs the sequent.

Ψ, Γ*, Π ⟶ Σ*, Ω₁

**M** no longer occurs in its antecedent, for Γ* does
not contain **M**, nor does Π, because of 3.121.22, and
Ψ contains at most one *side formula* of **If**, which can-
not be equal to **M**, since the *principal formula* of **If** is
equal to **M**.

Hence this mix, too, may be eliminated by virtue
of the induction hypothesis.

3.121.23. Suppose **If** is an inference figure with
*two* upper sequents, i.e., an &–*IS*, ∨–*IA*, or a
⊃–*IA*.

(In view of the application to intuitionist logic
(3.2) we shall deal with each possibility in greater
detail than would be necessary for the classical
case.)

3.121.231. Suppose **If** is an &–*IS*.

Then the end of the derivation runs:

```txt
       Γ ⟶ Θ, A      Γ ⟶ Θ, B
Π ⟶ Σ     Γ ⟶ Θ, A & B         &–IS
───────────────────────────── mix
    Π, Γ*⟶ Σ*, Θ, A & B
```

(**M** occurs in Γ.) This is transformed into:

```txt
Π ⟶ Σ   Γ ⟶ Θ, A           Π ⟶ Σ   Γ ⟶ Θ, B
─────────────────── mix     ─────────────────── mix
Π, Γ*⟶ Σ*, Θ, A            Π, Γ*⟶ Σ*, Θ, B
────────────────────────────────────────── &–IS
        Π, Γ*⟶ Σ*, Θ, A & B
```

Both mixes may be eliminated by virtue of the
induction hypothesis.

3.121.232. Suppose **If** is a ∨–*IA*.

Then the end of the derivation runs:

```txt
        A, Γ ⟶ Θ      B, Γ ⟶ Θ
Π ⟶ Σ     A ∨ B, Γ ⟶ Θ           ∨–IA
─────────────────────────────── mix
    Π, (A ∨ B)*, Γ*⟶ Σ*, Θ
```

((**A** ∨ **B**)* stands either for **A** ∨ **B** or for nothing
according as **A** ∨ **B** is unequal or equal to **M**.)

**M** certainly occurs in *Γ*. (For otherwise **M** would
be equal to **A** ∨ **B**, and the right rank would be
equal to 1 contrary to 3.121.)

To begin with, we transform the end of the
derivation into:

```txt
Π —→ Σ  A, Γ —→ Θ
―――――――――――――――――――― mix
Π, A*, Γ* —→ Σ*, Θ
―――――――――――――――――――― possibly several
A, Π, Γ* —→ Σ*, Θ   interchanges and
                     thinnings
―――――――――――――――――――――――――――――――――――――
        Π —→ Σ  B, Γ —→ Θ
        ―――――――――――――――――――― mix
        Π, B*, Γ* —→ Σ*, Θ
        ―――――――――――――――――――― possibly several
        B, Π, Γ* —→ Σ*, Θ   interchanges and
                             thinnings
―――――――――――――――――――――――――――――――――――――― ∨–IA.
        A ∨ B, Π, Γ* —→ Σ*, Θ
```

Both mixes may be eliminated by virtue of the
induction hypothesis.

From here on the procedure is the same as that in
3.121.221 and 3.121.222, i.e., we distinguish two cases
according as **A** ∨ **B** is unequal or equal to **M**. In the
first case we may have to add several interchanges to
obtain the endsequent of the original derivation;
in the second case we add a mix with *Π* —→ *Σ* to
its left-hand upper sequent, and thus once again
obtain the endsequent of the original derivation by
going on to perform a number of contractions and
interchanges, if necessary. The mix concerned may
be eliminated, since the associated right rank
equals 1. (All this is as in 3.121.222.)

3.121.233. Suppose **if** is a ⊃–*IA*.

Then the end of the derivation runs:

```txt
        Γ —→ Θ, A      B, Δ —→ Λ
Π —→ Σ  ―――――――――――――――――――――――――― ⊃–IA
        A ⊃ B, Γ, Δ —→ Θ, Λ
―――――――――――――――――――――――――――――――――――― mix
Π, (A ⊃ B)*, Γ*, Δ* —→ Σ*, Θ, Λ
```

3.121.2331. Suppose **M** occurs in *Γ* and *Δ*.

In that case we begin by transforming the
derivation into:

```txt
        Π —→ Σ  B, Δ —→ Λ
        ――――――――――――――――――― mix
        Π, B*, Δ* —→ Σ*, Λ
        ――――――――――――――――――― possibly several inter-
        B*, Π, Δ* —→ Σ*, Λ changes and thinnings
Π —→ Σ  Γ —→ Θ, A
―――――――――――――――――― mix
Π, Γ* —→ Σ*, Θ, A
―――――――――――――――――――――――――――――――――――――――― ⊃–IA
A ⊃ B, Π, Γ*, Π, Δ* —→ Σ*, Θ, Σ* Λ
```

Both mixes may be eliminated by virtue of the
induction hypothesis. Then we proceed as in
3.121.221 and 3.121.222. (All that may happen in
the first case is that beside interchanges a number of
contractions must be applied.)

3.121.233.2. Suppose **M** does not occur in both
*Γ* and *Δ* simultaneously. **M** must occur in either
*Γ* or *Δ* because of 3.121. Consider the case of **M**
occurring in *Δ* but not in *Γ*. The second case is
treated analogously.

The end of the derivation is transformed into:

```txt
         Π ⟶ Σ  B, Δ ⟶ Δ
         ―――――――――――――――――― mix
         Π, B*, Δ* ⟶ Σ*, Δ        possibly several
                                   exchanges and
Γ ⟶ Θ, A    B, Π, Δ* ⟶ Σ*, Δ     thinnings
―――――――――――――――――――――――――――――     ⊃-IA
    A ⊃ B, Γ, Π, Δ* ⟶ Θ, Σ*, Δ
```

The mix may be eliminated by virtue of the
induction hypothesis. We then proceed as in
3.121.221 and 3.121.222. (In the second case, where
**A ⊃ B** is equal to **M**, the right rank belonging to
the new mix equals 1 as always, since **M** does not
occur in **B**. *Π*, *Δ** for the usual reason, nor does it
occur in *Γ* according to the assumption of the
case under consideration.)

3.122. *Suppose the right rank is equal to 1*. In that
case the *left rank is greater than 1*.

This case is, in essence, treated symmetrically to
3.121. Special attention is required only for those
inference figures with no symmetric counterpart,
viz., the ⊃-*IS* and the ⊃-*IA*.

The inference figures If with *one* upper sequent
were incorporated, in 3.121.22, in the general
schema:

```txt
         Ψ, Γ ⟶ Ω₁
         ―――――――――――
         Ξ, Γ ⟶ Ω₂
```

The symmetric schema runs:

```txt
         Ω₁ ⟶ Γ, Ψ
         ―――――――――――
         Ω₂ ⟶ Γ, Ξ
```

which also includes a ⊃-*IS* without any further
change. (*Γ* here represents the formulae designated
by *Θ* in the schemata 1.21, 1.22.)

3.112.1. On the other hand, the case, where the
inference figure If is a ⊃-*IA*, must be treated
separately. Although this treatment will seem very
similar to that in 3.121.233, it is not entirely
symmetric.

Thus the end of the derivation runs:

```txt
    Γ ⟶ Θ, A  B, Δ ⟶ Δ
    ――――――――――――――――――――― ⊃-IA
    A ⊃ B, Γ, Δ ⟶ Θ, Δ         Σ* ⟶ Π
    ―――――――――――――――――――――――――――――――――――― mix
        A ⊃ B, Γ, Δ, Σ* ⟶ Θ*, Δ*, Π
```

3.122.11. Suppose **M** occurs both in *Θ* and *Δ*. In
that case we transform the end of the derivation

```
Γ ⟶ Θ, Λ   Σ ⟶ Π
―――――――――――――――――― mix
Γ, Σ*⟶ Θ*, Λ*, Π  possibly several
                    interchanges and
                    thinnings
                    B, Δ ⟶ Λ   Σ ⟶ Π
                    ――――――――――――――――― mix
                    B, Δ, Σ*⟶ Λ*, Π
――――――――――――――――――――――――――――――――――― possibly several
A ⊃ B, Γ, Σ*, Δ, Σ*⟶ Θ*, Π, Λ*, Π  contractions and
A ⊃ B, Γ, Δ, Σ*⟶ Θ*, Λ*, Π         interchanges.

Both mixes may be eliminated by virtue of the
induction hypothesis.

If the Σ-formula **M** does not occur in both Θ
and Λ simultaneously. It must occur in one of them.
We consider the case of **M** occurring in Λ but not
in Θ; the alternative case is completely analogous.

We transform the end of the derivation into:

                    B, Δ ⟶ Λ   Σ ⟶ Π
Γ ⟶ Θ, Λ           ――――――――――――――――― mix
                    B, Δ, Σ*⟶ Λ*, Π
―――――――――――――――――――――――――――――――――― ⊃-IΛ
A ⊃ B, Γ, Δ, Σ*⟶ Θ, Λ*, Π

The mix may be eliminated by virtue of the
induction hypothesis.

3.2. *Proof of the Hauptsatz for LJ-derivations.*

In order to transform an *LJ*-derivation into an
*LJ*-derivation *without cuts*, we apply *exactly the same
procedure* as for *LK*-derivations.

Since an *LJ*-derivation is a special case of an
*LK*-derivation, it is clear that the transformation
can be carried out. We have only to convince
ourselves that with every transformation step an
*LJ*-derivation becomes another *LJ*-derivation, i.e.,
that the consequents of the transformed derivation
do not contain more than one S-formula in the
succedent, given that this was the case before.

We therefore examine each step of the trans-
formation from that point of view.

3.21. Replacement of cuts by mixes. An *LJ*-cut
runs:

        Γ ⟶ D   D, Δ ⟶Λ
        ―――――――――――――――,
             Γ, Δ ⟶ Λ

where Λ contains at most one S-formula. We
transform this cut into:

Γ ⟶ D      D, Δ ⟶ Λ
――――――――――――――――――― mix
      Γ, Δ*⟶ Λ       possibly several interchanges
      ――――――――― Δ and thinnings in the ante-
      Γ, Δ ⟶Λ       cedent.

This replacement gives us a new *LJ*-derivation.

3.22. By replacing the free choice variable (3.10)
we trivially get another *LJ*-derivation from a
previous one.
```

3.23. The transformation proper (3.11 and 3.12).
We have to show for each of the cases 3.111 to
3.122.12 that the given transformations do not
introduce any sequents with more than one Σ-
formula in the succedent.

3.231. Let us begin with the cases 3.11:
In the cases 3.111, 3.113.1, 3.113.31, 3.113.35
and 3.113.36, only such formulae occur in each
succedent of the sequent of a new derivation as
already occurred in the succedent of the sequent of
the original derivation.

Essentially the same applies in 1.113.33. The
only difference is an additional substitution of free
object variables, which does not, of course, alter
the number of succedent formulae of a sequent.

Cases 3.112, 3.113.32, and 3.113.34 were dealt
with symmetrically to cases 3.111, 3.113.1,
3.113.31, and 3.113.33, i.e., in order to get one case
from another, we read the schemata from right to
left instead of from left to right (as well as changing
logical symbols, a process which is here of no
consequence). Hence in the antecedent of one case
we do precisely the same as in the succedent of
another. For the antecedents of cases 3.111, 3.113.1,
3.113.31 and 3.113.33, the same applies as for the
succedents, viz., in every antecedent of a sequent of
the new derivation only such formulae occur as
already occurred in an antecedent of a sequent of
the original derivation.

This disposes of all symmetric cases: 3.112,
3.113.2, 3.113.32 and 3.113.34.

3.23. Now let us look at the cases, 3.12:

3.232.1. For the cases 3.121 it holds generally
that Σ* is empty, since in Π → Σ, Σ must contain
only *one* formula, and this formula must be equal
to **M**.

It is now obvious that in every succedent of a
sequent only such formulae occur as already
occurred in the succedent of a sequent of the
original derivation.

3.232.2. In the cases 3.122 it is somewhat more
difficult to see that from an *LJ*-derivation we
always get another *LJ*-derivation. We must
direct our attention, as we have already done in
considering symmetric cases, to the *antecedents* in
the schemata 3.121.

At this point we distinguish two further sub-
cases:

3.232.21. The case which is symmetric to 3.121.1
is trivial, since in every antecedent of a sequent of
the new derivation (in case 3.121.1) only such
formulae occur as already occurred in an ante-
cedent of a sequent of the original derivation.

**3.232.22.** In the cases that are symmetric to
**3.121.2**, the mix in the end of the derivation runs:

```txt
      Ω —→ M   Σ —→ Π
      ——————————————————
         Ω, Σ*—→ Π
```

where *Π* contains at most *one* S-formula, and
where **Ω —→ M** is the lower sequent of an *LJ*-
inference figure in which at least one upper
sequent contains **M** as a succedent formula.

If we now look at the inference figure schemata
**1.21, 1.22**, it becomes easily apparent that such an
inference figure can only be a thinning, contraction,
or interchange in the antecedent, or a ∨-*IA*, a
&-*IA*, a ∃-*IA*, a ∀-*IA*, and a ⊃-*IA*. Let us
disregard for the moment the ∨-*IA* and the ⊃-*IA*.
Then all the possibilities enumerated above fall
within the case symmetric to **3.121.1**, where

both Ψ and Ξ always remain empty. (Γ corresponds
to the Θ of the inference figure.) Thus we have the
case which is symmetric to 3.121.221. Further-
more, Γ is equal to **M**, i.e., Γ* is empty, and Π
contains at most one formula. Hence, in the
derivation there never in fact occurs more than one
formula in the succedent of a sequent.

The case of a ∨-*IA* is symmetric to 3.121.231.
Again, Γ is equal to **M**, Γ* is empty, and Π con-
tains at most one formula; all is thus in order.

There now remains the case of a ⊃-*IA*, i.e.,
3.122.1. In an *LJ*- ⊃-*IA*, the Θ of the schema
(1.22) is empty. Thus we have the case set out
under 3.122.12. Λ* is also empty, and Π contains
at most one formula, which means that here, too,
we again obtain an *LJ*-derivation from an *LJ*-
derivation.

*All-Zeichen*—universal quantifier

*Annahmeformel*—assumption formula

*Antezedenz*—antecedent

*Äußerstes Zeichen*—terminal symbol

*Eigenvariable*—proper variable

*Es-gibt-Zeichen*—existential quantifier

*Faden*—branch

*Folge-Zeichen*—implication symbol

*Grad*—grade

*Grundformel*—basic formula

*Hauptformel*—principal formula

*Hauptsatz*—*Hauptsatz*

*Herleitung*—derivation

*Hilfssatz*—lemma

*Inhaltlicher Sinn*—intuitive sense

*Logische-Zeichen-Schlußfigur*—operational inference figure

*Mischformel*—mix formula

*Mischung*—mix

*Mittelungszeichen*—syntactic variable

*Nebenformel*—side formula

*Nicht-Zeichen*—negation symbol

*Oberformel*—upper formula  
*Obersequenz*—upper sequent  
*Oder-Zeichen*—disjunction symbol  
*Rang*—rank  
*Satz*—theorem  
*Schließen*—deduction  
*Schluß*—inference  
*Schnitt*—cut  
*Sequenz*—sequent  
*Spiegelbildlich*—dual  
*Stammbaumform*—tree form  
*Struktur-Schlußfigur*—structural inference figure  
*Sukzedenz*—succedent  
*Teilformel*—subformula  
*Und-Zeichen*—conjunction symbol  
*Untersequenz*—lower sequent  
*Verdünnung*—thinning  
*Vertauschung*—interchange  
*Zeichen für Bestimmtes*—constant symbol  
*Zusammenziehung*—contraction
